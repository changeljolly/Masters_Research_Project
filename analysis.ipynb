{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bash script to generate the BAM list for all BAM files\n",
    "import os\n",
    "\n",
    "# Directory where the BAM files are located\n",
    "bam_directory = 'path/to/BAM/files/data'\n",
    "# Directory where the output files should be saved\n",
    "output_directory = 'path/to/save/list'\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Get a list of all BAM files in the directory\n",
    "bam_files = sorted([f for f in os.listdir(bam_directory) if f.endswith('.bam')])\n",
    "\n",
    "# Create an individual file for each BAM file\n",
    "for idx, bam_file in enumerate(bam_files, start=1):\n",
    "    file_path = os.path.join(bam_directory, bam_file)\n",
    "    output_file = os.path.join(output_directory, f'ID{idx}_list.lst')\n",
    "    \n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(f\"ID{idx},{file_path}\\n\")\n",
    "\n",
    "print(f\"Formatted list files saved to {output_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bash script to generate the region list for all BAM files\n",
    "\n",
    "# Generate lists of chrX where X ranges from 1 to 22\n",
    "chromosomes = ['chr' + str(x) for x in range(1, 23)]\n",
    "\n",
    "# Iterate through each chromosome and create a corresponding file\n",
    "for chromosome in chromosomes:\n",
    "    filename = chromosome + '.lst'\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(chromosome + '\\n')\n",
    "    print(f\"Created file: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cluster job script for Data Preprocessing\n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "# Define paths\n",
    "path=\"/path/to/cloned/dir/of/Monopogen\"\n",
    "list_dir=\"path/to/list\"\n",
    "base_output_dir=\"path/to/save/output\"\n",
    "scripts_dir=\"path/to/preprocess/scripts\"\n",
    "\n",
    "# Set the library path\n",
    "export LD_LIBRARY_PATH=\"${path}/apps:$LD_LIBRARY_PATH\"\n",
    "echo $LD_LIBRARY_PATH\n",
    "\n",
    "# Ensure base output directory exists\n",
    "mkdir -p $base_output_dir\n",
    "\n",
    "# Loop through each list file, sorted numerically, and submit a SLURM job for each\n",
    "for list_file in $(ls ${list_dir}/ID*_list.lst | sort -V); do\n",
    "    # Extract the ID from the list file name\n",
    "    filename=$(basename -- \"$list_file\")\n",
    "    id=\"${filename%_list.lst}\"\n",
    "\n",
    "    # Create a unique output directory for this dataset\n",
    "    output_dir=\"${base_output_dir}/${id}\"\n",
    "    mkdir -p $output_dir\n",
    "\n",
    "    echo \"Preprocessing ${list_file} with output to ${output_dir}...\"\n",
    "\n",
    "    # Run the preprocessing job script\n",
    "    sbatch ${scripts_dir}/Preprocess.sh ${path}/src/Monopogen.py ${list_file} ${output_dir} 8\n",
    "\n",
    "done\n",
    "\n",
    "echo \"Preprocessing submitted for all files.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cluster job script for Germline Call\n",
    "# Only 5 datasets were used due to technical issues\n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "# Number of datasets\n",
    "num_datasets=5\n",
    "\n",
    "# Template file\n",
    "template_file=\"path/to/alt_germline.sh\"\n",
    "\n",
    "# Loop over each dataset\n",
    "for dataset_id in $(seq 1 $num_datasets); do\n",
    "  # Create a SLURM script for the current dataset\n",
    "  job_script=\"run_germline_c20_ID${dataset_id}.sh\"\n",
    "  sed \"s/{{DATASET_ID}}/${dataset_id}/g\" $template_file > $job_script\n",
    "\n",
    "  # Submit the job script\n",
    "  echo \"Submitting job script for Dataset ID: $dataset_id\"\n",
    "  sbatch $job_script\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Somatic Calling, the code remains the same as Monopogen Git Repository has provided\n",
    "#This was done for all 5 IDs individually\n",
    "#Scripts and Outputs are saved under respective folder in respective ID folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Result Analysis\n",
    "\n",
    "import pandas as pd\n",
    "import gzip\n",
    "\n",
    "# Load the filtered_ID1.csv file to get the list of IDs\n",
    "filtered_ids_df = pd.read_csv('path/to/filtered_ID1.csv')\n",
    "\n",
    "# Display the dataframe\n",
    "filtered_ids_df.head(), filtered_ids_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the chr20.gl.filter.hc.cell.mat.gz file\n",
    "with gzip.open('path/to/chr20.gl.filter.hc.cell.mat.gz', 'rt') as f:\n",
    "    chr20_df = pd.read_csv(f, sep='\\t', header=None)\n",
    "\n",
    "# Rename the first four columns\n",
    "chr20_df.rename(columns={0: \"chr\", 1: \"pos\", 2: \"ref_ale\", 3: \"alt_ale\"}, inplace=True)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "chr20_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 'chr' and 'pos' columns from the filtered_ids_df\n",
    "filtered_chr = filtered_ids_df['chr'].iloc[0]\n",
    "filtered_pos = filtered_ids_df['pos'].iloc[0]\n",
    "\n",
    "# Filter the chr20_df based on the 'chr' and 'pos' columns\n",
    "filtered_chr20_df = chr20_df[(chr20_df['chr'] == filtered_chr) & (chr20_df['pos'] == filtered_pos)]\n",
    "\n",
    "# Display the filtered dataframe\n",
    "filtered_chr20_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the order of columns: 1-4, 19-20, and then the rest\n",
    "columns_to_display = list(filtered_chr20_df.columns[:4])+list(filtered_chr20_df.columns[18:])\n",
    "\n",
    "# Reorder the dataframe based on the new column order\n",
    "reordered_df = filtered_chr20_df[columns_to_display]\n",
    "\n",
    "# Display the reordered dataframe\n",
    "display(reordered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the file to replace the column header with single-cell sequences\n",
    "cell_seq_file = pd.read_csv(\"path/to/chr20.cell_snv.cellID.filter.csv\", usecols=['cell'])\n",
    "\n",
    "#Transpose the rows to columns\n",
    "cell_seq = cell_seq_file.T\n",
    "\n",
    "#Display the single-cell sequences\n",
    "display(cell_seq)\n",
    "\n",
    "# Extract the headers from the transposed cell sequence dataframe\n",
    "new_headers = cell_seq.iloc[0, :].tolist()\n",
    "\n",
    "# Create new column names for reordered_df starting from the 6th column onward\n",
    "new_column_names = list(reordered_df.columns[:4]) + new_headers\n",
    "\n",
    "# Check if the lengths match\n",
    "if len(new_column_names) == len(reordered_df.columns):\n",
    "    # Rename the columns in reordered_df\n",
    "    reordered_df.columns = new_column_names\n",
    "    # Display the reordered dataframe with the new column names\n",
    "    display(reordered_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorize Mutation Types\n",
    "\n",
    "# Function to classify mutation status\n",
    "def mutation(value):\n",
    "    if value == '0/0':\n",
    "        return '0'\n",
    "    elif value in ['1/0', '0/1', '1/1']:\n",
    "        return '1'\n",
    "    else:\n",
    "        return value \n",
    "\n",
    "# Apply the function to all columns in the reordered dataframe\n",
    "mutation_df = reordered_df.map(mutation)\n",
    "\n",
    "# Display the dataframe\n",
    "print(mutation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Cells with this particular Mutation\n",
    "\n",
    "# Create a new column indicating the number of mutations in each row\n",
    "mutation_df['mutation_count'] = mutation_df.apply(lambda row: sum(1 for val in row if val == '1'), axis=1)\n",
    "\n",
    "final_df = mutation_df\n",
    "\n",
    "# Display the final dataframe\n",
    "print(final_df)\n",
    "\n",
    "# Create a column with information of col 1-4 is merged to one\n",
    "\n",
    "def generate_names(df):\n",
    "    df['snvID'] = df['snvID'] = df.apply(lambda row: f\"{row[0]}:{row[1]}:{row[2]}:{row[3]}\", axis=1)\n",
    "    return df\n",
    "\n",
    "snv_id_set = generate_names(final_df)\n",
    "\n",
    "print(snv_id_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No of cells having particular mutations\n",
    "\n",
    "# Identify columns with 'mutation' values\n",
    "mutation_columns = mutation_df.columns[mutation_df.eq('1').any()]\n",
    "\n",
    "# Convert the index object to a list\n",
    "mutation_columns_list = mutation_columns.tolist()\n",
    "\n",
    "# Create a new dataframe from the list\n",
    "cell_mut_df = pd.DataFrame(mutation_columns_list, columns=['Mutation_Columns'])\n",
    "\n",
    "# Display the new dataframe\n",
    "print(cell_mut_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the sequence and get info from Randolph metadata\n",
    "\n",
    "# Load Randolph metadata TSV file\n",
    "import re\n",
    "randolph_metadata = pd.read_csv('path/to/Randolph_singlecell_metadata.tsv', sep='\\t')\n",
    "\n",
    "# Extract sequence from cell_mut_df\n",
    "cell_mut_df['Extracted_CellID'] = cell_mut_df['Mutation_Columns'].apply(lambda x: re.match(r'([^-\\d]+)', x).group(1))\n",
    "\n",
    "# Extract sequence from randolph_metadata\n",
    "randolph_metadata['Extracted_CellID'] = randolph_metadata['CellID'].apply(lambda x: re.search(r'_([^_]+)$', x).group(1))\n",
    "\n",
    "# Merge the DataFrames on the extracted cell IDs\n",
    "merged_df = pd.merge(cell_mut_df, randolph_metadata, on='Extracted_CellID', how='left')\n",
    "\n",
    "display(merged_df[['Extracted_CellID', 'celltype', 'Batch']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the results to the batch ID for the partiular dataset\n",
    "\n",
    "# [batch ID data retrieved from sra metadata file] for eg: B1_c1\n",
    "\n",
    "# Define the batch identifier to filter by\n",
    "batch_to_filter = 'B1_c1'\n",
    "\n",
    "# Filter the DataFrame for the specific batch identifier\n",
    "filtered_df = merged_df[merged_df['Batch'] == batch_to_filter]\n",
    "count_rows = len(filtered_df)\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(f'Total number of cells with this mutation = {count_rows}')\n",
    "display(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell Type Count for Mutated \n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(filtered_df)\n",
    "\n",
    "# Group by SOC_indiv_ID and then count occurrences of each cell type within each group\n",
    "cell_type_counts = df.groupby('SOC_indiv_ID')['celltype'].value_counts()\n",
    "\n",
    "# List unique cell types\n",
    "unique_cell_types = df['celltype'].unique()\n",
    "\n",
    "# Display results\n",
    "print(\"Cell Type Counts by SOC_indiv_ID:\")\n",
    "print(cell_type_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve age from donor metadata\n",
    "\n",
    "# Read the donor metadata file\n",
    "donor_metadata_df = pd.read_csv('path/to/donor_metadata_with_batchid.csv')\n",
    "\n",
    "#Selecting the required columns\n",
    "donor_age_df = donor_metadata_df[['indiv_ID', 'batchID', 'age']]\n",
    "# Merge the DataFrames\n",
    "result_df = pd.merge(filtered_df, donor_age_df, left_on=['SOC_indiv_ID', 'Batch'], right_on=['indiv_ID', 'batchID'], how='left')\n",
    "\n",
    "# Display the result\n",
    "count_rows = len(result_df)\n",
    "print(f'No. of Rows = {count_rows}')\n",
    "display(result_df[['Extracted_CellID', 'SOC_indiv_ID','celltype', 'Batch', 'age', 'SOC_infection_status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For check total cells present in the sample\n",
    "\n",
    "# Extract column headers\n",
    "headers = mutation_df.columns.tolist()\n",
    "\n",
    "# Slice headers after the 4th column\n",
    "headers_after_4th = headers[4:5947]\n",
    "\n",
    "total_cells_list = [{'Column': header} for header in headers_after_4th]\n",
    "cell_total_df = pd.DataFrame(total_cells_list)\n",
    "\n",
    "# Display the new DataFrame\n",
    "count_rows = len(cell_total_df)\n",
    "print(f'Total number of columns after the 4th column = {count_rows}')\n",
    "\n",
    "# Load Randolph metadata TSV file\n",
    "randolph_metadata = pd.read_csv('path/to/Randolph_singlecell_metadata.tsv', sep='\\t')\n",
    "\n",
    "# Extract sequence from cell_mut_df\n",
    "cell_total_df['Extracted_CellID'] = cell_total_df['Column'].apply(lambda x: re.match(r'([^-\\d]+)', x).group(1))\n",
    "\n",
    "# Extract sequence from randolph_metadata\n",
    "randolph_metadata['Extracted_CellID'] = randolph_metadata['CellID'].apply(lambda x: re.search(r'_([^_]+)$', x).group(1))\n",
    "\n",
    "# Merge the DataFrames on the extracted cell IDs\n",
    "merged_total_df = pd.merge(cell_total_df, randolph_metadata, on='Extracted_CellID', how='left')\n",
    "\n",
    "count_rows = len(merged_total_df)\n",
    "print(f'Total number of cells = {count_rows}')\n",
    "print(merged_total_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For calculating total cells present in this sample\n",
    "\n",
    "# Define the batch identifier to filter by\n",
    "filter_batch = 'B1_c1'\n",
    "\n",
    "# Filter the DataFrame for the specific batch identifier\n",
    "sort_cell_total_df = merged_total_df[merged_total_df['Batch'] == filter_batch]\n",
    "count_rows = len(sort_cell_total_df)\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(f'Total number of cells = {count_rows}')\n",
    "display(sort_cell_total_df[['Extracted_CellID','celltype', 'Batch', 'SOC_indiv_ID', 'SOC_infection_status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Cell Type Count\n",
    "\n",
    "# Create DataFrame\n",
    "total_df = pd.DataFrame(sort_cell_total_df)\n",
    "\n",
    "# Group by SOC_indiv_ID and then count occurrences of each cell type within each group\n",
    "total_cell_type_counts = total_df.groupby('SOC_indiv_ID')['celltype'].value_counts()\n",
    "\n",
    "# Display results\n",
    "print(\"Cell Type Counts:\", total_cell_type_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mutation Rate Calculation\n",
    "\n",
    "# Create DataFrames\n",
    "mutation_cell_type_df = pd.DataFrame(cell_type_counts)\n",
    "total_cell_type_df = pd.DataFrame(total_cell_type_counts)\n",
    "\n",
    "# Group by SOC_indiv_ID and celltype to sum total occurrences\n",
    "total_cell_type_counts = total_cell_type_df.groupby(['SOC_indiv_ID', 'celltype']).sum().reset_index().rename(columns={'count': 'total_cell_type_count'})\n",
    "\n",
    "# Group by SOC_indiv_ID and celltype to sum mutated occurrences\n",
    "mutation_cell_type_counts = mutation_cell_type_df.groupby(['SOC_indiv_ID', 'celltype']).sum().reset_index().rename(columns={'count': 'mut_cell_type_count'})\n",
    "\n",
    "# Merge the DataFrames on 'SOC_indiv_ID' and 'celltype'\n",
    "mutation_rate_df = pd.merge(total_cell_type_counts, mutation_cell_type_counts, on=['SOC_indiv_ID', 'celltype'], how='left')\n",
    "\n",
    "# Define the human chr20 length\n",
    "chromosome_length = 64444167 \n",
    "\n",
    "# Calculate the mutation rate for each cell type\n",
    "mutation_rate_df['mutation_rate'] = mutation_rate_df['mut_cell_type_count'] / mutation_rate_df['total_cell_type_count'] / chromosome_length\n",
    "\n",
    "# Display results\n",
    "count_rows = len(mutation_rate_df)\n",
    "print(f'Total number of rows = {count_rows}')\n",
    "display(\"Cell Type Counts by SOC_indiv_ID and Mutation Rates:\", mutation_rate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter and Remove the NaN values from Mutation Rate Calculation\n",
    "\n",
    "# Sort the DataFrame by SOC_indiv_ID and celltype\n",
    "mutation_rate_df_sorted = mutation_rate_df.sort_values(by=['SOC_indiv_ID', 'celltype'])\n",
    "\n",
    "# Remove rows with NaN values\n",
    "mutation_rate_df_clean = mutation_rate_df_sorted.dropna(subset=['mut_cell_type_count'])\n",
    "\n",
    "# Display results and the new DataFrame\n",
    "count_rows = len(mutation_rate_df_clean)\n",
    "print(f'Total number of rows = {count_rows}')\n",
    "display(\"Cell Type Counts by SOC_indiv_ID and Mutation Rates (Sorted):\", mutation_rate_df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve Age information\n",
    "\n",
    "# Merge the DataFrames on SOC_indiv_ID and indiv_ID\n",
    "age_cell_df = pd.merge(mutation_rate_df_clean, donor_age_df, left_on='SOC_indiv_ID', right_on='indiv_ID', how='left')\n",
    "\n",
    "# Drop unnecessary columns from donor_age_df if needed (e.g., 'indiv_ID' column)\n",
    "age_cell_df = age_cell_df.drop(columns=['indiv_ID'])\n",
    "\n",
    "# Display the updated DataFrame with age information\n",
    "count_rows = len(age_cell_df)\n",
    "print(f'Total number of rows = {count_rows}')\n",
    "\n",
    "# Filter rows where batchID is 'B1_c1'\n",
    "result_filtered_df1 = age_cell_df.loc[age_cell_df['batchID'] == 'B1_c1']\n",
    "\n",
    "# Display the filtered DataFrame and count of rows\n",
    "count_filtered_rows = len(result_filtered_df1)\n",
    "print(f'Total number of rows for batchID B1_c1 = {count_filtered_rows}')\n",
    "display(\"Filtered DataFrame with Age Information for batchID B1_c1:\", result_filtered_df1)\n",
    "\n",
    "# Save the dataframe to .csv file\n",
    "result_filtered_df1.to_csv('path/to/save/file/result_filtered_df1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Graphs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Ensure the DataFrame has no NaN values in 'age' or 'mutation_rate'\n",
    "result_filtered_df = result_filtered_df1.dropna(subset=['age', 'mutation_rate'])\n",
    "\n",
    "# Get unique cell types\n",
    "cell_types = result_filtered_df['celltype'].unique()\n",
    "\n",
    "# Define a color palette for cell types\n",
    "palette = sns.color_palette(\"husl\", len(cell_types))  # Using a distinct color palette\n",
    "\n",
    "# Create a figure and axis\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot each cell type with different colors\n",
    "for i, cell_type in enumerate(cell_types):\n",
    "    cell_subset = result_filtered_df[result_filtered_df['celltype'] == cell_type]\n",
    "    \n",
    "    # Check if cell_subset is not empty\n",
    "    if cell_subset.empty:\n",
    "        continue\n",
    "    \n",
    "    # Plot scatter plot\n",
    "    sns.scatterplot(x='age', y='mutation_rate', data=cell_subset, color=palette[i], marker='o', label=cell_type)\n",
    "    \n",
    "    # Check if there is variation in 'age' values\n",
    "    if len(cell_subset['age'].unique()) > 1:\n",
    "        # Fit line of best fit\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(cell_subset['age'], cell_subset['mutation_rate'])\n",
    "        \n",
    "        # Generate line of best fit\n",
    "        age_range = np.linspace(cell_subset['age'].min(), cell_subset['age'].max(), 100)\n",
    "        mutation_rate_fit = intercept + slope * age_range\n",
    "        \n",
    "        # Plot line of best fit with label\n",
    "        plt.plot(age_range, mutation_rate_fit, color=palette[i], linestyle='--',\n",
    "                 label=f'{cell_type} Fit: y={slope:.2f}x+{intercept:.2f}, R²={r_value**2:.2f}')\n",
    "    else:\n",
    "        print(f\"Not enough variation in 'age' values for cell type: {cell_type}\")\n",
    "\n",
    "# Set titles and labels\n",
    "plt.title('Mutation Rate vs Age')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Mutation Rate')\n",
    "plt.legend()\n",
    "\n",
    "# Adjust layout and show plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a summary table of the graph\n",
    "\n",
    "# Ensure the DataFrame has no NaN values in 'age' or 'mutation_rate'\n",
    "result_filtered_df = result_filtered_df1.dropna(subset=['age', 'mutation_rate'])\n",
    "\n",
    "# Get unique cell types\n",
    "cell_types = result_filtered_df['celltype'].unique()\n",
    "\n",
    "# Prepare lists to hold the summary information\n",
    "summary_data = {\n",
    "    'Cell Type': [],\n",
    "    'Slope': [],\n",
    "    'Intercept': [],\n",
    "    'R-squared': [],\n",
    "    'P-value': [],\n",
    "    'Std Error': []\n",
    "}\n",
    "\n",
    "# Calculate regression parameters for each cell type\n",
    "for cell_type in cell_types:\n",
    "    cell_subset = result_filtered_df[result_filtered_df['celltype'] == cell_type]\n",
    "    \n",
    "    # Check if there is variation in 'age' values\n",
    "    if len(cell_subset['age'].unique()) > 1:\n",
    "        # Perform linear regression\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(cell_subset['age'], cell_subset['mutation_rate'])\n",
    "        \n",
    "        # Append the results to the summary data\n",
    "        summary_data['Cell Type'].append(cell_type)\n",
    "        summary_data['Slope'].append(slope)\n",
    "        summary_data['Intercept'].append(intercept)\n",
    "        summary_data['R-squared'].append(r_value**2)\n",
    "        summary_data['P-value'].append(p_value)\n",
    "        summary_data['Std Error'].append(std_err)\n",
    "    else:\n",
    "        print(f\"Not enough variation in 'age' values for cell type: {cell_type}\")\n",
    "        \n",
    "# Create a DataFrame from the summary data\n",
    "summary_df1 = pd.DataFrame(summary_data)\n",
    "\n",
    "# Display the summary table\n",
    "summary_df1[['Cell Type', 'Slope', 'Intercept', 'R-squared']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all datasets to plot graph for combined mutation rate vs age\n",
    "import pandas as pd\n",
    "\n",
    "# List of file paths\n",
    "file_paths = [\"define/path/to/result_filtered_df1.csv\", \"../result_filtered_df2.csv\" ..... \"./nth file.csv\"]\n",
    "\n",
    "# Load all CSV files into DataFrames\n",
    "dataframes = [pd.read_csv(file_path) for file_path in file_paths]\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Drop rows with NaN values in 'age' or 'mutation_rate'\n",
    "combined_df = combined_df.dropna(subset=['age', 'mutation_rate'])\n",
    "\n",
    "# Ensure 'celltype' column is treated as categorical\n",
    "combined_df['celltype'] = combined_df['celltype'].astype('category')\n",
    "\n",
    "display(combined_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the cell types with < 3 data points\n",
    "\n",
    "# Count data points for each cell type\n",
    "cell_type_counts = combined_df['celltype'].value_counts()\n",
    "\n",
    "# Filter cell types with at least 3 data points\n",
    "valid_cell_types = cell_type_counts[cell_type_counts >= 3].index\n",
    "\n",
    "# Filter combined DataFrame to include only valid cell types\n",
    "filtered_df = combined_df[combined_df['celltype'].isin(valid_cell_types)]\n",
    "\n",
    "display(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Define a color palette for valid cell types\n",
    "cell_types = filtered_df['celltype'].unique()\n",
    "palette = sns.color_palette(\"husl\", len(cell_types))\n",
    "\n",
    "# Initialize a list to hold summary data\n",
    "summary_data = []\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot each valid cell type with different colors\n",
    "for i, cell_type in enumerate(cell_types):\n",
    "    cell_subset = filtered_df[filtered_df['celltype'] == cell_type]\n",
    "    \n",
    "    # Check if cell_subset is not empty\n",
    "    if cell_subset.empty:\n",
    "        continue\n",
    "    \n",
    "    # Check if there is variation in 'age' values\n",
    "    if len(cell_subset['age'].unique()) > 1:\n",
    "        # Fit line of best fit\n",
    "        slope, intercept, r_value, _, _ = stats.linregress(cell_subset['age'], cell_subset['mutation_rate'])\n",
    "        \n",
    "        # Append to summary data\n",
    "        summary_data.append({\n",
    "            'Cell Type': cell_type,\n",
    "            'Slope': slope,\n",
    "            'Intercept': intercept,\n",
    "            'R²': r_value**2\n",
    "        })\n",
    "        \n",
    "        # Generate line of best fit\n",
    "        age_range = np.linspace(cell_subset['age'].min(), cell_subset['age'].max(), 100)\n",
    "        mutation_rate_fit = intercept + slope * age_range\n",
    "        \n",
    "        # Plot line of best fit with label\n",
    "        plt.plot(age_range, mutation_rate_fit, color=palette[i], linestyle='--',\n",
    "                 label=f'{cell_type} Fit: y={slope:.2f}x+{intercept:.2f}, R²={r_value**2:.2f}')\n",
    "    else:\n",
    "        print(f\"Not enough variation in 'age' values for cell type: {cell_type}\")\n",
    "\n",
    "# Plot scatter points for each cell type\n",
    "sns.scatterplot(data=filtered_df, x='age', y='mutation_rate', hue='celltype', palette=palette, marker='o')\n",
    "\n",
    "# Set titles and labels\n",
    "plt.title('Combined Mutation Rate vs Age Across Cell Types')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Mutation Rate')\n",
    "plt.legend(title='Cell Type')\n",
    "\n",
    "# Adjust layout to prevent overlap and show plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create a DataFrame from the summary data\n",
    "summary_df = pd.DataFrame(summary_data)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
